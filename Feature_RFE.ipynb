{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4qn3QHD7PGGDmJnXnwM34",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prince545/ml-learning/blob/main/Feature_RFE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I446Tx5D08jj",
        "outputId": "535128a4-460d-4678-c41d-1fee455e91ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Model Accuracy (All Features): 79.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RFE Model Accuracy (5 Features): 77.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RFE Model Accuracy (10 Features): 77.2\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv(\"/content/WA_Fn-UseC_-Telco-Customer-Churn.csv\")  # Replace with your actual file name\n",
        "\n",
        "# Data Cleaning\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df.drop(columns=['customerID'], inplace=True)\n",
        "\n",
        "# One-Hot Encoding\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Features and Target\n",
        "X = df.drop(columns=['Churn_Yes'])\n",
        "y = df['Churn_Yes']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
        "\n",
        "# Base Model (All Features)\n",
        "base_model = LogisticRegression(max_iter=1000)\n",
        "base_model.fit(X_train, y_train)\n",
        "y_pred_base = base_model.predict(X_test)\n",
        "accuracy_base = round(accuracy_score(y_test, y_pred_base) * 100, 2)\n",
        "print(\"Base Model Accuracy (All Features):\", accuracy_base)\n",
        "\n",
        "# RFE with 5 Features\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "rfe = RFE(model, n_features_to_select=5)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "selected_features = X_train.columns[rfe.support_]\n",
        "X_train_rfe = X_train[selected_features]\n",
        "X_test_rfe = X_test[selected_features]\n",
        "\n",
        "model.fit(X_train_rfe, y_train)\n",
        "y_pred_rfe = model.predict(X_test_rfe)\n",
        "accuracy_rfe = round(accuracy_score(y_test, y_pred_rfe) * 100, 2)\n",
        "print(\"RFE Model Accuracy (5 Features):\", accuracy_rfe)\n",
        "\n",
        "# RFE with 10 Features\n",
        "model2 = LogisticRegression(max_iter=1000)\n",
        "rfe2 = RFE(model2, n_features_to_select=10)\n",
        "rfe2.fit(X_train, y_train)\n",
        "\n",
        "selected_features_10 = X_train.columns[rfe2.support_]\n",
        "X_train_rfe_10 = X_train[selected_features_10]\n",
        "X_test_rfe_10 = X_test[selected_features_10]\n",
        "\n",
        "model2.fit(X_train_rfe_10, y_train)\n",
        "y_pred_rfe_10 = model2.predict(X_test_rfe_10)\n",
        "accuracy_rfe_10 = round(accuracy_score(y_test, y_pred_rfe_10) * 100, 2)\n",
        "print(\"RFE Model Accuracy (10 Features):\", accuracy_rfe_10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your data (replace with your actual data loading method)\n",
        "# Example:\n",
        "# df = pd.read_csv(\"your_dataset.csv\")\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop('target_column', axis=1)  # Replace 'target_column' with actual target\n",
        "y = df['target_column']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# =============================\n",
        "# Standard Scaling\n",
        "# =============================\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# =============================\n",
        "# Base Model (All Features)\n",
        "# =============================\n",
        "base_model = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
        "base_model.fit(X_train_scaled, y_train)\n",
        "y_pred_base = base_model.predict(X_test_scaled)\n",
        "print(\"Base Model Accuracy (All Features): {:.2f}\".format(accuracy_score(y_test, y_pred_base) * 100))\n",
        "\n",
        "# =============================\n",
        "# RFE with 5 Features\n",
        "# =============================\n",
        "model_5 = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
        "rfe_5 = RFE(model_5, n_features_to_select=5)\n",
        "rfe_5.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Select top 5 features\n",
        "X_train_rfe_5 = rfe_5.transform(X_train_scaled)\n",
        "X_test_rfe_5 = rfe_5.transform(X_test_scaled)\n",
        "\n",
        "# Train and predict\n",
        "model_5.fit(X_train_rfe_5, y_train)\n",
        "y_pred_rfe_5 = model_5.predict(X_test_rfe_5)\n",
        "print(\"RFE Model Accuracy (5 Features): {:.2f}\".format(accuracy_score(y_test, y_pred_rfe_5) * 100))\n",
        "\n",
        "# =============================\n",
        "# RFE with 10 Features\n",
        "# =============================\n",
        "model_10 = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
        "rfe_10 = RFE(model_10, n_features_to_select=10)\n",
        "rfe_10.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Select top 10 features\n",
        "X_train_rfe_10 = rfe_10.transform(X_train_scaled)\n",
        "X_test_rfe_10 = rfe_10.transform(X_test_scaled)\n",
        "\n",
        "# Train and predict\n",
        "model_10.fit(X_train_rfe_10, y_train)\n",
        "y_pred_rfe_10 = model_10.predict(X_test_rfe_10)\n",
        "print(\"RFE Model Accuracy (10 Features): {:.2f}\".format(accuracy_score(y_test, y_pred_rfe_10) * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "QZEbe75-1rMG",
        "outputId": "5f5cbe91-9bd7-4568-ca82-029c278b537a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['target_column'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-2458471643.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Define features and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target_column'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace 'target_column' with actual target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_column'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['target_column'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv(\"/content/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "\n",
        "# Data Cleaning\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df.drop(columns=['customerID'], inplace=True)\n",
        "\n",
        "# One-Hot Encoding\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Features and Target\n",
        "X = df.drop(columns=['Churn_Yes'])\n",
        "y = df['Churn_Yes']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ========================================\n",
        "# Base Model (All Features)\n",
        "# ========================================\n",
        "base_model = LogisticRegression(max_iter=2000)\n",
        "base_model.fit(X_train_scaled, y_train)\n",
        "y_pred_base = base_model.predict(X_test_scaled)\n",
        "accuracy_base = round(accuracy_score(y_test, y_pred_base) * 100, 2)\n",
        "print(\"Base Model Accuracy (All Features):\", accuracy_base)\n",
        "\n",
        "# ========================================\n",
        "# RFE with 5 Features\n",
        "# ========================================\n",
        "model_5 = LogisticRegression(max_iter=2000)\n",
        "rfe_5 = RFE(model_5, n_features_to_select=5)\n",
        "rfe_5.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Feature Names\n",
        "selected_features_5 = X.columns[rfe_5.support_]\n",
        "print(\"Top 5 Selected Features:\", list(selected_features_5))\n",
        "\n",
        "# Train and Evaluate\n",
        "X_train_rfe_5 = rfe_5.transform(X_train_scaled)\n",
        "X_test_rfe_5 = rfe_5.transform(X_test_scaled)\n",
        "model_5.fit(X_train_rfe_5, y_train)\n",
        "y_pred_rfe_5 = model_5.predict(X_test_rfe_5)\n",
        "accuracy_rfe_5 = round(accuracy_score(y_test, y_pred_rfe_5) * 100, 2)\n",
        "print(\"RFE Model Accuracy (5 Features):\", accuracy_rfe_5)\n",
        "\n",
        "# ========================================\n",
        "# RFE with 10 Features\n",
        "# ========================================\n",
        "model_10 = LogisticRegression(max_iter=2000)\n",
        "rfe_10 = RFE(model_10, n_features_to_select=10)\n",
        "rfe_10.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Feature Names\n",
        "selected_features_10 = X.columns[rfe_10.support_]\n",
        "print(\"Top 10 Selected Features:\", list(selected_features_10))\n",
        "\n",
        "# Train and Evaluate\n",
        "X_train_rfe_10 = rfe_10.transform(X_train_scaled)\n",
        "X_test_rfe_10 = rfe_10.transform(X_test_scaled)\n",
        "model_10.fit(X_train_rfe_10, y_train)\n",
        "y_pred_rfe_10 = model_10.predict(X_test_rfe_10)\n",
        "accuracy_rfe_10 = round(accuracy_score(y_test, y_pred_rfe_10) * 100, 2)\n",
        "print(\"RFE Model Accuracy (10 Features):\", accuracy_rfe_10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOXVS79Q1-dH",
        "outputId": "d3cf0946-57ef-43a8-f03a-40b2797a00a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Model Accuracy (All Features): 79.43\n",
            "Top 5 Selected Features: ['tenure', 'TotalCharges', 'InternetService_Fiber optic', 'OnlineSecurity_No internet service', 'Contract_Two year']\n",
            "RFE Model Accuracy (5 Features): 77.96\n",
            "Top 10 Selected Features: ['tenure', 'MonthlyCharges', 'TotalCharges', 'InternetService_Fiber optic', 'OnlineSecurity_No internet service', 'StreamingTV_Yes', 'StreamingMovies_No internet service', 'StreamingMovies_Yes', 'Contract_One year', 'Contract_Two year']\n",
            "RFE Model Accuracy (10 Features): 78.63\n"
          ]
        }
      ]
    }
  ]
}